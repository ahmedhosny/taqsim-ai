"""
Simple Interactive Embedding Visualizer for MAEST Audio Embeddings

This script provides functions to:
1. Load audio embeddings generated by the MAEST model
2. Reduce their dimensionality using UMAP
3. Create an interactive visualization with Altair
"""

import glob
import os
import re

import altair as alt
import numpy as np
import pandas as pd
from umap import UMAP


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}

    # Find all .npz files in the embeddings directory
    embedding_files = glob.glob(
        os.path.join(embeddings_dir, "embeddings_youtube_*.npz")
    )

    for file_path in embedding_files:
        # Extract video ID from filename
        match = re.search(
            r"embeddings_youtube_([^.]+)\.npz", os.path.basename(file_path)
        )
        if match:
            video_id = match.group(1)

            # Load the embeddings
            try:
                embeddings = np.load(file_path)

                # Store embeddings by video ID
                all_embeddings[video_id] = {
                    key: embeddings[key] for key in embeddings.keys()
                }

                print(
                    f"Loaded embeddings for video {video_id} with {len(embeddings.keys())} chunks"
                )
            except Exception as e:
                print(f"Error loading embeddings from {file_path}: {e}")

    return all_embeddings


def get_metadata_from_csv(video_ids):
    """
    Get metadata for the given video IDs from the CSV file.

    Args:
        video_ids: List of video IDs to find metadata for

    Returns:
        Dictionary mapping video IDs to dictionaries of metadata
    """
    # Initialize with default values
    metadata = {
        vid: {
            "song_name": "Unknown",
            "artist": "Unknown",
            "maqam": "Unknown",
            "type": "Unknown",
            "electric": "Unknown",
            "vintage": "Unknown",
            "link": "Unknown",
        }
        for vid in video_ids
    }

    try:
        # Get the path to the CSV file
        csv_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "data",
            "taqsim_ai.csv",
        )

        if os.path.exists(csv_path):
            # Read the CSV file using pandas
            df = pd.read_csv(csv_path)

            if not df.empty and "link" in df.columns:
                # Get all column names except 'link'
                metadata_columns = [col for col in df.columns if col != "link"]

                # Process each row in the dataframe
                for _, row in df.iterrows():
                    try:
                        # Extract video ID from the YouTube link
                        url = row["link"]
                        video_id = url.split("v=")[1]
                        if "&" in video_id:
                            video_id = video_id.split("&")[0]

                        # If this video ID is in our list, extract all metadata
                        if video_id in video_ids:
                            # Create a dictionary with all available metadata
                            video_metadata = {}
                            for col in metadata_columns:
                                # Use empty string if the value is NaN
                                value = row[col] if pd.notna(row[col]) else "Unknown"
                                video_metadata[col] = value

                            # Add the original YouTube link to the metadata
                            video_metadata["link"] = url

                            metadata[video_id] = video_metadata
                            print(f"Found metadata for video {video_id}")
                    except Exception as e:
                        print(f"Error processing row in CSV: {e}")
            else:
                print("CSV file is empty or missing required columns.")
        else:
            print(f"CSV file not found at {csv_path}")
    except Exception as e:
        print(f"Error reading metadata from CSV: {e}")

    return metadata


def prepare_embeddings_for_umap(all_embeddings, embedding_type="cls"):
    """
    Prepare embeddings for UMAP by extracting the specified embedding type.

    Args:
        all_embeddings: Dictionary of embeddings by video ID
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Each embedding is shape [3, 768] where:
            # embedding[0] = CLS token embedding
            # embedding[1] = DIST token embedding
            # embedding[2] = Average of other token embeddings
            if embedding_type == "cls":
                embeddings_list.append(embedding[0])
            elif embedding_type == "dist":
                embeddings_list.append(embedding[1])
            elif embedding_type == "avg":
                embeddings_list.append(embedding[2])
            elif embedding_type == "combined":
                # Concatenate all three embeddings
                embeddings_list.append(
                    np.concatenate([embedding[0], embedding[1], embedding[2]])
                )

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    return np.array(embeddings_list), video_ids_list, chunk_numbers


def create_visualization(
    embeddings_dir, embedding_type="cls", output_dir=None, html_filename=None
):
    """
    Create a simple interactive visualization of the embeddings using Altair.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        output_dir: Directory to save the HTML file (if None, current directory is used)
        html_filename: Name of the HTML file to save (if None, a default name is used)

    Returns:
        Path to the saved HTML file
    """
    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)

    if not all_embeddings:
        print("No embeddings found in the specified directory.")
        return None

    # Prepare embeddings for UMAP
    embeddings, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type
    )

    # Get metadata for all video IDs
    unique_video_ids = list(set(video_ids))
    metadata_by_video = get_metadata_from_csv(unique_video_ids)

    # Reduce dimensionality with UMAP
    print(f"Reducing dimensionality with UMAP (embedding type: {embedding_type})...")
    reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
    embedding_2d = reducer.fit_transform(embeddings)

    # Create a DataFrame for Altair with all metadata
    df_data = {
        "x": embedding_2d[:, 0],
        "y": embedding_2d[:, 1],
        "video_id": video_ids,
        "chunk_number": chunk_numbers,
    }

    # Add all metadata columns
    metadata_columns = [
        "song_name",
        "artist",
        "maqam",
        "type",
        "electric",
        "vintage",
        "link",
    ]
    for column in metadata_columns:
        df_data[column] = [
            metadata_by_video.get(vid, {}).get(column, "Unknown") for vid in video_ids
        ]

    # Create the DataFrame
    df = pd.DataFrame(df_data)

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Create a dropdown parameter for selecting the coloring attribute
    # Position it at the top of the chart
    color_by = alt.param(
        name="color_by",
        value="song_name",  # Default to song_name
        bind=alt.binding_select(
            options=["song_name", "artist", "maqam", "type", "electric", "vintage"],
            labels=["Song Name", "Artist", "Maqam", "Type", "Electric", "Vintage"],
            name="Color by: ",
            # Position at the top
            debounce=10,  # Small delay to make selection smoother
        ),
    )

    # Create a selection for zooming
    zoom = alt.selection_interval(bind="scales")

    # Create a toggle for lines positioned at the top
    show_lines = alt.param(
        name="show_lines",
        value=True,
        bind=alt.binding_checkbox(name="Show connecting lines "),
    )

    # Create a toggle for chunk numbers
    show_numbers = alt.param(
        name="show_numbers",
        value=True,
        bind=alt.binding_checkbox(name="Show chunk numbers "),
    )

    # Create a dynamic legend selection based on the color_by parameter
    # This will update when the dropdown changes
    # fields=['color_value'] ensures the selection works with the dynamic color field
    legend_selection = alt.selection_point(
        fields=["color_value"], bind="legend", name="Legend_Selection"
    )

    # Base chart
    base = (
        alt.Chart(df)
        .encode(
            x=alt.X("x:Q", title="UMAP Dimension 1"),
            y=alt.Y("y:Q", title="UMAP Dimension 2"),
        )
        .add_params(color_by, zoom)
    )

    # Create lines between consecutive chunks
    lines_data = []
    for vid in df["video_id"].unique():
        vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
        if len(vid_df) > 1:
            for i in range(len(vid_df) - 1):
                line_data = {
                    "x1": vid_df.iloc[i]["x"],
                    "y1": vid_df.iloc[i]["y"],
                    "x2": vid_df.iloc[i + 1]["x"],
                    "y2": vid_df.iloc[i + 1]["y"],
                }
                # Add all metadata columns
                for col in [
                    "song_name",
                    "artist",
                    "maqam",
                    "type",
                    "electric",
                    "vintage",
                    "link",
                ]:
                    line_data[col] = vid_df.iloc[i][col]

                lines_data.append(line_data)

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data) if lines_data else pd.DataFrame()

    # Create a new field for dynamic coloring based on the dropdown selection
    # Also create a title field that will be used for the legend title
    base = base.transform_calculate(
        color_value=f"datum[{color_by.name}]",  # This creates a field that changes with the dropdown
        title_value=f"{color_by.name}",  # This will be used for the legend title
    )

    # Do the same for the lines DataFrame if it's not empty
    if not lines_df.empty:
        lines_chart = alt.Chart(lines_df).transform_calculate(
            color_value=f"datum[{color_by.name}]",  # Same dynamic field for lines
            title_value=f"{color_by.name}",  # Same title field for lines
        )

        # Draw lines with the dynamic color
        lines = (
            lines_chart.transform_filter(show_lines)  # Only when toggle is on
            .mark_rule()
            .encode(
                x="x1:Q",
                y="y1:Q",
                x2="x2:Q",
                y2="y2:Q",
                opacity=alt.condition(
                    legend_selection,
                    alt.value(0.6),  # Higher opacity when selected
                    alt.value(0.01),  # Lower opacity when not selected
                ),
                color=alt.Color(
                    "color_value:N",  # Use the calculated field
                    legend=None,  # No legend for lines
                ),
            )
        )
    else:
        lines = alt.Chart().mark_rule()  # Empty chart

    # Draw points with the dynamic color
    points = (
        base.mark_circle(size=100)
        .encode(
            opacity=alt.condition(legend_selection, alt.value(1.0), alt.value(0.05)),
            tooltip=[
                "song_name:N",
                "artist:N",
                "maqam:N",
                "type:N",
                "electric:N",
                "vintage:N",
                "link:N",
                "video_id:N",
                "chunk_number:Q",
            ],
            color=alt.Color(
                "color_value:N",  # Use the calculated field
                # title=f"{color_by.value}",  # Simple fixed title
                legend=alt.Legend(
                    orient="right",
                    labelLimit=300,
                    titleFontSize=14,
                    labelFontSize=12,
                    symbolSize=100,
                    symbolLimit=300,
                ),
            ),
        )
        .add_params(legend_selection, show_lines, show_numbers)
    )

    # Create a separate DataFrame for the labels with the same positioning as the circles
    label_df = df.copy()
    # Use the same coordinates as the circles (no offset)
    # We'll position the text directly on the circles

    # Create a text layer with the separate DataFrame
    # Create a text layer that will be conditionally displayed based on the show_numbers parameter
    text = (
        alt.Chart(label_df)
        .mark_text(align="center", baseline="middle", fontSize=6, fontWeight="bold")
        .encode(
            x="x:Q",
            y="y:Q",  # Use the same y-coordinate as the circles
            text="chunk_number:Q",
            color=alt.value("black"),  # Black text as requested
            opacity=alt.condition(legend_selection, alt.value(1), alt.value(0)),
        )
        .transform_calculate(
            color_value=f"datum[{color_by.name}]"  # Add this for selection to work
        )
        # Only show this layer when show_numbers is true
        .transform_filter(show_numbers)
    )

    # Create the final chart
    chart = (
        alt.layer(lines, points, text)
        .properties(
            width=800,  # Slightly smaller to leave room for legend
            height=700,
            title=f"UMAP Visualization of MAEST {embedding_type.upper()} Embeddings",
            padding={
                "left": 50,
                "top": 50,
                "right": 150,
                "bottom": 50,
            },  # Add padding for legend
        )
        .configure_view(stroke=None)
        .configure_axis(grid=True, gridOpacity=0.2)
        .configure_legend(
            orient="right",
            symbolSize=100,
            labelLimit=500,
            padding=10,
            offset=5,  # Move legend away from the chart
            titleFontSize=14,
            labelFontSize=12,
            strokeColor="gray",
            fillColor="#ffffff",
            cornerRadius=5,
            legendX=820,  # Position legend explicitly
            legendY=100,
        )
        .resolve_scale(
            color="independent"  # Make color scale independent of other scales
        )
    )

    # Save the chart to an HTML file
    if html_filename is None:
        html_filename = f"maest_{embedding_type}_embeddings_interactive.html"
    if output_dir is not None:
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, html_filename)
    else:
        output_path = html_filename

    chart.save(output_path)
    print(f"Interactive visualization saved to {output_path}")

    return output_path


def create_all_visualizations(embeddings_dir, output_dir=None):
    """
    Create visualizations for all embedding types.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        output_dir: Directory to save the HTML files

    Returns:
        List of paths to the saved HTML files
    """
    embedding_types = ["cls", "dist", "avg", "combined"]
    output_paths = []

    for embedding_type in embedding_types:
        print(f"\nCreating visualization for {embedding_type.upper()} embeddings...")
        output_path = create_visualization(
            embeddings_dir=embeddings_dir,
            embedding_type=embedding_type,
            output_dir=output_dir,
        )
        if output_path:
            output_paths.append(output_path)

    return output_paths


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Create interactive visualizations of MAEST audio embeddings"
    )
    parser.add_argument(
        "--embeddings_dir", default=None, help="Directory containing embedding files"
    )
    parser.add_argument(
        "--output_dir", default=None, help="Directory to save HTML files"
    )
    parser.add_argument(
        "--embedding_type",
        default="all",
        choices=["cls", "dist", "avg", "combined", "all"],
        help="Type of embedding to visualize",
    )

    args = parser.parse_args()

    # If embeddings_dir not specified, use default data/embeddings directory
    if args.embeddings_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # If output_dir not specified, use default data/visualizations directory
    if args.output_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.output_dir = os.path.join(project_dir, "data", "visualizations")

    # Create output directory if specified
    if args.output_dir:
        os.makedirs(args.output_dir, exist_ok=True)

    if args.embedding_type == "all":
        create_all_visualizations(args.embeddings_dir, args.output_dir)
    else:
        create_visualization(
            embeddings_dir=args.embeddings_dir,
            embedding_type=args.embedding_type,
            output_dir=args.output_dir,
        )
