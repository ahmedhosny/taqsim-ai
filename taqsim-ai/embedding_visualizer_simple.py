"""
Simple Interactive Embedding Visualizer for MAEST Audio Embeddings

This script provides functions to:
1. Load audio embeddings generated by the MAEST model
2. Reduce their dimensionality using UMAP
3. Create an interactive visualization with Altair
"""

import glob
import os
import re

import altair as alt
import numpy as np
import pandas as pd
from umap import UMAP


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}

    # Find all .npz files in the embeddings directory
    embedding_files = glob.glob(
        os.path.join(embeddings_dir, "embeddings_youtube_*.npz")
    )

    for file_path in embedding_files:
        # Extract video ID from filename
        match = re.search(
            r"embeddings_youtube_([^.]+)\.npz", os.path.basename(file_path)
        )
        if match:
            video_id = match.group(1)

            # Load the embeddings
            try:
                embeddings = np.load(file_path)

                # Store embeddings by video ID
                all_embeddings[video_id] = {
                    key: embeddings[key] for key in embeddings.keys()
                }

                print(
                    f"Loaded embeddings for video {video_id} with {len(embeddings.keys())} chunks"
                )
            except Exception as e:
                print(f"Error loading embeddings from {file_path}: {e}")

    return all_embeddings


def get_song_names(downloads_dir, video_ids):
    """
    Get song names for the given video IDs from the downloads directory.

    Args:
        downloads_dir: Path to the downloads directory
        video_ids: List of video IDs to find song names for

    Returns:
        Dictionary mapping video IDs to song names
    """
    song_names = {}

    for vid in video_ids:
        song_name = "Unknown"
        try:
            # Look for files with this video ID in the filename
            # Format can be either:
            # 1. youtube_videoID_title.wav
            # 2. title_videoID.wav
            matching_files = [
                f
                for f in os.listdir(downloads_dir)
                if (
                    f.startswith(f"youtube_{vid}")
                    or f.endswith(f"_{vid}.wav")
                    or f.endswith(f"_{vid}.mp3")
                )
                and os.path.isfile(os.path.join(downloads_dir, f))
            ]

            if matching_files:
                file_name = matching_files[0]
                # Get the filename without extension
                song_name = os.path.splitext(file_name)[0]

                # Handle different filename formats
                if song_name.startswith(f"youtube_{vid}_"):
                    # Format: youtube_videoID_title
                    song_name = song_name[len(f"youtube_{vid}_") :]
                elif song_name.startswith(f"youtube_{vid}"):
                    # Format: youtube_videoID
                    song_name = song_name[len(f"youtube_{vid}") :]
                elif song_name.endswith(f"_{vid}"):
                    # Format: title_videoID
                    song_name = song_name[: -len(f"_{vid}")]

                print(f"Found song name for video {vid}: {song_name}")
        except Exception as e:
            print(f"Error finding song name for video {vid}: {e}")

        song_names[vid] = song_name

    return song_names


def prepare_embeddings_for_umap(all_embeddings, embedding_type="cls"):
    """
    Prepare embeddings for UMAP by extracting the specified embedding type.

    Args:
        all_embeddings: Dictionary of embeddings by video ID
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Each embedding is shape [3, 768] where:
            # embedding[0] = CLS token embedding
            # embedding[1] = DIST token embedding
            # embedding[2] = Average of other token embeddings
            if embedding_type == "cls":
                embeddings_list.append(embedding[0])
            elif embedding_type == "dist":
                embeddings_list.append(embedding[1])
            elif embedding_type == "avg":
                embeddings_list.append(embedding[2])
            elif embedding_type == "combined":
                # Concatenate all three embeddings
                embeddings_list.append(
                    np.concatenate([embedding[0], embedding[1], embedding[2]])
                )

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    return np.array(embeddings_list), video_ids_list, chunk_numbers


def create_visualization(
    embeddings_dir, embedding_type="cls", output_dir=None, html_filename=None
):
    """
    Create a simple interactive visualization of the embeddings using Altair.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        output_dir: Directory to save the HTML file (if None, current directory is used)
        html_filename: Name of the HTML file to save (if None, a default name is used)

    Returns:
        Path to the saved HTML file
    """
    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)

    if not all_embeddings:
        print("No embeddings found in the specified directory.")
        return None

    # Prepare embeddings for UMAP
    embeddings, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type
    )

    # Get the downloads directory to find song names
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    downloads_dir = os.path.join(project_dir, "data", "downloads")

    # Get song names for all video IDs
    unique_video_ids = list(set(video_ids))
    song_names = get_song_names(downloads_dir, unique_video_ids)

    # Reduce dimensionality with UMAP
    print(f"Reducing dimensionality with UMAP (embedding type: {embedding_type})...")
    reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
    embedding_2d = reducer.fit_transform(embeddings)

    # Create a DataFrame for Altair
    df = pd.DataFrame(
        {
            "x": embedding_2d[:, 0],
            "y": embedding_2d[:, 1],
            "video_id": video_ids,
            "chunk_number": chunk_numbers,
            "song_name": [song_names.get(vid, "Unknown") for vid in video_ids],
            "tooltip": [
                f"Song: {song_names.get(vid, 'Unknown')}\nVideo ID: {vid}\nChunk: {num}"
                for vid, num in zip(video_ids, chunk_numbers)
            ],
        }
    )

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Create a selection that allows selecting songs by clicking on points
    selection = alt.selection_point(fields=["song_name"], bind="legend")

    # Create a toggle for lines
    show_lines = alt.param(
        name="show_lines",
        value=True,
        bind=alt.binding_checkbox(name="Show connecting lines"),
    )

    # Create a zoom selection
    zoom = alt.selection_interval(bind="scales")

    # Base chart
    base = alt.Chart(df).encode(
        x=alt.X("x:Q", title="UMAP Dimension 1"),
        y=alt.Y("y:Q", title="UMAP Dimension 2"),
        color=alt.Color(
            "song_name:N",
            legend=alt.Legend(
                title="Songs",
                orient="right",
                labelLimit=600,  # Much larger limit to prevent truncation
                direction="vertical",
                symbolLimit=0,
            ),
        ),
    )

    # Create lines between consecutive chunks (drawn first, so they appear behind points)
    lines_data = []
    for vid in df["video_id"].unique():
        vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
        if len(vid_df) > 1:
            for i in range(len(vid_df) - 1):
                lines_data.append(
                    {
                        "x1": vid_df.iloc[i]["x"],
                        "y1": vid_df.iloc[i]["y"],
                        "x2": vid_df.iloc[i + 1]["x"],
                        "y2": vid_df.iloc[i + 1]["y"],
                        "song_name": vid_df.iloc[i]["song_name"],
                    }
                )

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data)

    # Draw lines (only if there are any)
    if not lines_df.empty:
        # Create separate charts for lines with different conditions
        # Lines for selected songs when toggle is on
        lines_selected_on = (
            alt.Chart(lines_df)
            .transform_filter(
                show_lines  # Only when toggle is on
            )
            .mark_rule(color="black", opacity=0.5)
            .encode(x="x1:Q", y="y1:Q", x2="x2:Q", y2="y2:Q")
        )

        # Apply selection filter to the lines
        lines = lines_selected_on.transform_filter(
            selection  # Only for selected songs
        )
    else:
        lines = alt.Chart().mark_rule()  # Empty chart

    # Draw points
    points = (
        base.mark_circle(size=100)
        .encode(
            opacity=alt.condition(selection, alt.value(0.9), alt.value(0.2)),
            tooltip=["tooltip:N"],
        )
        .add_params(selection, show_lines, zoom)
    )

    # Draw text labels (on top of points)
    text = base.mark_text(
        align="center",
        baseline="middle",
        fontWeight="bold",
        fontSize=9,
        color="black",  # Always black text
    ).encode(
        text="chunk_number:Q",
        color=alt.value("black"),  # Explicitly set text color in encoding
        opacity=alt.condition(selection, alt.value(1), alt.value(0)),
    )

    # Combine all layers
    chart = (
        alt.layer(
            lines,  # Lines at the bottom
            points,  # Points in the middle
            text,  # Text on top
        )
        .properties(
            width=800,
            height=600,
            title=f"UMAP Visualization of MAEST {embedding_type.upper()} Embeddings",
        )
        .configure_view(stroke=None)
        .configure_axis(grid=True, gridOpacity=0.2)
        .configure_legend(
            titleFontSize=14,
            labelFontSize=12,
            symbolSize=150,
            labelLimit=800,  # Significantly increased label limit for legend
            symbolLimit=0,
            columns=1,
            padding=20,  # Add padding around legend
            cornerRadius=5,  # Rounded corners for legend
            labelOverlap=False,  # Prevent label overlap
        )
    )

    # Save the chart to an HTML file
    if html_filename is None:
        html_filename = f"maest_{embedding_type}_embeddings_interactive.html"
    if output_dir is not None:
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, html_filename)
    else:
        output_path = html_filename

    chart.save(output_path)
    print(f"Interactive visualization saved to {output_path}")

    return output_path


def create_all_visualizations(embeddings_dir, output_dir=None):
    """
    Create visualizations for all embedding types.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        output_dir: Directory to save the HTML files

    Returns:
        List of paths to the saved HTML files
    """
    embedding_types = ["cls", "dist", "avg", "combined"]
    output_paths = []

    for embedding_type in embedding_types:
        print(f"\nCreating visualization for {embedding_type.upper()} embeddings...")
        output_path = create_visualization(
            embeddings_dir=embeddings_dir,
            embedding_type=embedding_type,
            output_dir=output_dir,
        )
        if output_path:
            output_paths.append(output_path)

    return output_paths


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Create interactive visualizations of MAEST audio embeddings"
    )
    parser.add_argument(
        "--embeddings_dir", default=None, help="Directory containing embedding files"
    )
    parser.add_argument(
        "--output_dir", default=None, help="Directory to save HTML files"
    )
    parser.add_argument(
        "--embedding_type",
        default="all",
        choices=["cls", "dist", "avg", "combined", "all"],
        help="Type of embedding to visualize",
    )

    args = parser.parse_args()

    # If embeddings_dir not specified, use default data/embeddings directory
    if args.embeddings_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # If output_dir not specified, use default data/visualizations directory
    if args.output_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.output_dir = os.path.join(project_dir, "data", "visualizations")

    # Create output directory if specified
    if args.output_dir:
        os.makedirs(args.output_dir, exist_ok=True)

    if args.embedding_type == "all":
        create_all_visualizations(args.embeddings_dir, args.output_dir)
    else:
        create_visualization(
            embeddings_dir=args.embeddings_dir,
            embedding_type=args.embedding_type,
            output_dir=args.output_dir,
        )
