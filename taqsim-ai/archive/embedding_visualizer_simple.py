"""
Simple Interactive Embedding Visualizer for MAEST Audio Embeddings

This script provides functions to:
1. Load audio embeddings generated by the MAEST model
2. Reduce their dimensionality using UMAP
3. Create an interactive visualization with Altair
"""

import glob
import os

import altair as alt
import numpy as np
import pandas as pd
from umap import UMAP


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.
    Works with the new structure where each chunk has its own NPZ file.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}

    # Find all .npz files in the embeddings directory
    # The pattern is: {uuid}_{chunk_number}_{start_second}_{end_second}.npz
    embedding_files = glob.glob(os.path.join(embeddings_dir, "*.npz"))

    for file_path in embedding_files:
        # Extract video ID and chunk number from filename
        # Pattern: {uuid}_{chunk_number}_{start_second}_{end_second}.npz
        basename = os.path.basename(file_path)
        # Remove the extension to get the base name
        base_name_no_ext = os.path.splitext(basename)[0]
        # Split by underscore to get components
        parts = base_name_no_ext.split("_")

        # Need at least 4 parts: uuid, chunk_number, start_second, end_second
        if len(parts) >= 4:
            # The UUID could contain underscores, so we need to be careful
            # The chunk number is always the second-to-last element before the timestamps
            # Assuming format is {uuid}_{chunk_number}_{start}_{end}
            # where chunk_number, start, and end are all numeric

            # Try to find where the numeric parts start
            numeric_indices = [i for i, part in enumerate(parts) if part.isdigit()]

            if numeric_indices:
                # The first numeric part should be the chunk number
                chunk_num_index = numeric_indices[0]
                # UUID is everything before the chunk number
                video_id = "_".join(parts[:chunk_num_index])
                # Chunk number is at the chunk_num_index
                try:
                    chunk_num = int(parts[chunk_num_index])

                    # Initialize dict for this video if not already present
                    if video_id not in all_embeddings:
                        all_embeddings[video_id] = {}

                    # Load the embedding for this chunk
                    try:
                        embedding_data = np.load(file_path)

                        # The key in the NPZ file should be 'embedding'
                        if "embedding" in embedding_data:
                            # Store under chunk_{number} key to maintain compatibility
                            chunk_key = f"chunk_{chunk_num}"
                            all_embeddings[video_id][chunk_key] = embedding_data[
                                "embedding"
                            ]
                        else:
                            print(f"Warning: No 'embedding' key found in {file_path}")

                    except Exception as e:
                        print(f"Error loading embedding from {file_path}: {e}")
                except ValueError:
                    print(f"Could not parse chunk number from {basename}")
            else:
                print(f"No numeric parts found in filename: {basename}")
        else:
            print(f"Filename does not match expected pattern: {basename}")

    # Print summary of loaded embeddings
    for video_id, chunks in all_embeddings.items():
        print(f"Loaded embeddings for video {video_id} with {len(chunks)} chunks")

    return all_embeddings


def get_metadata_from_csv(video_ids):
    """
    Get metadata for the given UUIDs from the CSV file.
    Works with the new pipeline where UUIDs are used instead of YouTube video IDs.

    Args:
        video_ids: List of UUIDs to find metadata for

    Returns:
        Dictionary mapping UUIDs to dictionaries of metadata
    """
    # Initialize with default values
    metadata = {
        vid: {
            "song_name": "Unknown",
            "artist": "Unknown",
            "maqam": "Unknown",
            "type": "Unknown",
            "electric": "Unknown",
            "vintage": "Unknown",
            "link": "Unknown",
        }
        for vid in video_ids
    }

    try:
        # Get the path to the CSV file
        csv_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "data",
            "taqsim_ai.csv",
        )

        if os.path.exists(csv_path):
            # Read the CSV file using pandas
            df = pd.read_csv(csv_path)

            if not df.empty:
                # Check if the CSV has the required columns
                if "uuid" not in df.columns:
                    print(
                        "Warning: CSV file is missing 'uuid' column. Cannot match metadata."
                    )
                    return metadata

                # Get all column names for metadata
                metadata_columns = [col for col in df.columns if col != "uuid"]

                # Process each row in the dataframe
                for _, row in df.iterrows():
                    try:
                        # Get the UUID directly from the row
                        if "uuid" in row:
                            uuid = str(
                                row["uuid"]
                            )  # Convert to string to ensure matching

                            # If this UUID is in our list, extract all metadata
                            if uuid in video_ids:
                                # Create a dictionary with all available metadata
                                video_metadata = {}
                                for col in metadata_columns:
                                    # Use "Unknown" if the value is NaN
                                    value = (
                                        row[col] if pd.notna(row[col]) else "Unknown"
                                    )
                                    video_metadata[col] = value

                                metadata[uuid] = video_metadata
                                print(f"Found metadata for UUID {uuid}")
                    except Exception as e:
                        print(f"Error processing row in CSV: {e}")
            else:
                print("CSV file is empty.")
        else:
            print(f"CSV file not found at {csv_path}")

        # Print summary of metadata matching
        found_count = sum(
            1 for vid in video_ids if metadata[vid]["song_name"] != "Unknown"
        )
        print(f"Found metadata for {found_count} out of {len(video_ids)} UUIDs")

    except Exception as e:
        print(f"Error reading metadata from CSV: {e}")

    return metadata


def prepare_embeddings_for_umap(all_embeddings, embedding_type="cls"):
    """
    Prepare embeddings for UMAP by extracting the specified embedding type.
    Works with the new embedding structure where each chunk has its own embedding file.

    Args:
        all_embeddings: Dictionary of embeddings by video ID
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Check the shape of the embedding to determine its structure
            if len(embedding.shape) == 2 and embedding.shape[0] == 3:
                # Original format with [3, 768] shape where:
                # embedding[0] = CLS token embedding
                # embedding[1] = DIST token embedding
                # embedding[2] = Average of other token embeddings
                if embedding_type == "cls":
                    embeddings_list.append(embedding[0])
                elif embedding_type == "dist":
                    embeddings_list.append(embedding[1])
                elif embedding_type == "avg":
                    embeddings_list.append(embedding[2])
                elif embedding_type == "combined":
                    # Concatenate all three embeddings
                    embeddings_list.append(
                        np.concatenate([embedding[0], embedding[1], embedding[2]])
                    )
            else:
                # New format where the embedding is already a single vector
                # Just use the embedding directly regardless of embedding_type
                # This handles the case where the embedding is a flattened vector
                embeddings_list.append(embedding)
                print(
                    f"Using new embedding format for {video_id} chunk {chunk_num} with shape {embedding.shape}"
                )

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    if not embeddings_list:
        print(
            "Warning: No embeddings were processed. Check if the embedding files exist and have the correct format."
        )
        return np.array([]), [], []

    return np.array(embeddings_list), video_ids_list, chunk_numbers


def create_visualization(
    embeddings_dir, embedding_type="cls", output_dir=None, html_filename=None
):
    """
    Create a simple interactive visualization of the embeddings using Altair.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        output_dir: Directory to save the HTML file (if None, current directory is used)
        html_filename: Name of the HTML file to save (if None, a default name is used)

    Returns:
        Path to the saved HTML file
    """
    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)

    if not all_embeddings:
        print("No embeddings found in the specified directory.")
        return None

    # Prepare embeddings for UMAP
    embeddings, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type
    )

    # Get metadata for all video IDs
    unique_video_ids = list(set(video_ids))
    metadata_by_video = get_metadata_from_csv(unique_video_ids)

    # Reduce dimensionality with UMAP
    print(f"Reducing dimensionality with UMAP (embedding type: {embedding_type})...")
    reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
    embedding_2d = reducer.fit_transform(embeddings)

    # Create a DataFrame for Altair with all metadata
    df_data = {
        "x": embedding_2d[:, 0],
        "y": embedding_2d[:, 1],
        "video_id": video_ids,
        "chunk_number": chunk_numbers,
    }

    # Add all metadata columns
    metadata_columns = [
        "song_name",
        "artist",
        "maqam",
        "type",
        "electric",
        "vintage",
        "link",
    ]

    # Print some debug information
    print(f"Found {len(unique_video_ids)} unique video IDs in embeddings")
    print(f"Found metadata for {len(metadata_by_video)} video IDs")

    # Create a mapping from each video_id to its metadata
    # This ensures consistent metadata for all chunks from the same video
    for column in metadata_columns:
        column_values = []
        for vid in video_ids:
            # Get metadata for this video ID
            metadata = metadata_by_video.get(vid, {})
            value = metadata.get(column, "Unknown")
            column_values.append(value)
        df_data[column] = column_values

    # Create the DataFrame
    df = pd.DataFrame(df_data)

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Create a dropdown parameter for selecting the coloring attribute
    # Position it at the top of the chart
    color_by = alt.param(
        name="color_by",
        value="song_name",  # Default to song_name
        bind=alt.binding_select(
            options=["song_name", "artist", "maqam", "type", "electric", "vintage"],
            labels=["Song Name", "Artist", "Maqam", "Type", "Electric", "Vintage"],
            name="Color by: ",
            # Position at the top
            debounce=10,  # Small delay to make selection smoother
        ),
    )

    # Create a selection for zooming
    zoom = alt.selection_interval(bind="scales")

    # Create a toggle for lines positioned at the top
    show_lines = alt.param(
        name="show_lines",
        value=True,
        bind=alt.binding_checkbox(name="Show connecting lines "),
    )

    # Create a toggle for chunk numbers
    show_numbers = alt.param(
        name="show_numbers",
        value=True,
        bind=alt.binding_checkbox(name="Show chunk numbers "),
    )

    # Create a dynamic legend selection based on the color_by parameter
    # This will update when the dropdown changes
    # fields=['color_value'] ensures the selection works with the dynamic color field
    legend_selection = alt.selection_point(
        fields=["color_value"], bind="legend", name="Legend_Selection"
    )

    # Base chart
    base = (
        alt.Chart(df)
        .encode(
            x=alt.X("x:Q", title="UMAP Dimension 1"),
            y=alt.Y("y:Q", title="UMAP Dimension 2"),
        )
        .add_params(color_by, zoom)
    )

    # Create lines between consecutive chunks
    lines_data = []
    for vid in df["video_id"].unique():
        vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
        if len(vid_df) > 1:
            for i in range(len(vid_df) - 1):
                line_data = {
                    "x1": vid_df.iloc[i]["x"],
                    "y1": vid_df.iloc[i]["y"],
                    "x2": vid_df.iloc[i + 1]["x"],
                    "y2": vid_df.iloc[i + 1]["y"],
                }
                # Add all metadata columns
                for col in [
                    "song_name",
                    "artist",
                    "maqam",
                    "type",
                    "electric",
                    "vintage",
                    "link",
                ]:
                    line_data[col] = vid_df.iloc[i][col]

                lines_data.append(line_data)

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data) if lines_data else pd.DataFrame()

    # Create a new field for dynamic coloring based on the dropdown selection
    # Also create a title field that will be used for the legend title
    base = base.transform_calculate(
        color_value=f"datum[{color_by.name}]",  # This creates a field that changes with the dropdown
        title_value=f"{color_by.name}",  # This will be used for the legend title
    )

    # Do the same for the lines DataFrame if it's not empty
    if not lines_df.empty:
        lines_chart = alt.Chart(lines_df).transform_calculate(
            color_value=f"datum[{color_by.name}]",  # Same dynamic field for lines
            title_value=f"{color_by.name}",  # Same title field for lines
        )

        # Draw lines with the dynamic color
        lines = (
            lines_chart.transform_filter(show_lines)  # Only when toggle is on
            .mark_rule()
            .encode(
                x="x1:Q",
                y="y1:Q",
                x2="x2:Q",
                y2="y2:Q",
                opacity=alt.condition(
                    legend_selection,
                    alt.value(0.6),  # Higher opacity when selected
                    alt.value(0.01),  # Lower opacity when not selected
                ),
                color=alt.Color(
                    "color_value:N",  # Use the calculated field
                    legend=None,  # No legend for lines
                ),
            )
        )
    else:
        lines = alt.Chart().mark_rule()  # Empty chart

    # Draw points with the dynamic color
    points = (
        base.mark_circle(size=100)
        .encode(
            opacity=alt.condition(legend_selection, alt.value(1.0), alt.value(0.05)),
            tooltip=[
                "song_name:N",
                "artist:N",
                "maqam:N",
                "type:N",
                "electric:N",
                "vintage:N",
                "link:N",
                "video_id:N",
                "chunk_number:Q",
            ],
            color=alt.Color(
                "color_value:N",  # Use the calculated field
                # title=f"{color_by.value}",  # Simple fixed title
                legend=alt.Legend(
                    orient="right",
                    labelLimit=300,
                    titleFontSize=14,
                    labelFontSize=12,
                    symbolSize=100,
                    symbolLimit=300,
                ),
            ),
        )
        .add_params(legend_selection, show_lines, show_numbers)
    )

    # Create a separate DataFrame for the labels with the same positioning as the circles
    label_df = df.copy()
    # Use the same coordinates as the circles (no offset)
    # We'll position the text directly on the circles

    # Create a text layer with the separate DataFrame
    # Create a text layer that will be conditionally displayed based on the show_numbers parameter
    text = (
        alt.Chart(label_df)
        .mark_text(align="center", baseline="middle", fontSize=6, fontWeight="bold")
        .encode(
            x="x:Q",
            y="y:Q",  # Use the same y-coordinate as the circles
            text="chunk_number:Q",
            color=alt.value("black"),  # Black text as requested
            opacity=alt.condition(legend_selection, alt.value(1), alt.value(0)),
        )
        .transform_calculate(
            color_value=f"datum[{color_by.name}]"  # Add this for selection to work
        )
        # Only show this layer when show_numbers is true
        .transform_filter(show_numbers)
    )

    # Create the final chart
    chart = (
        alt.layer(lines, points, text)
        .properties(
            width=800,  # Slightly smaller to leave room for legend
            height=700,
            title=f"UMAP Visualization of MAEST {embedding_type.upper()} Embeddings",
            padding={
                "left": 50,
                "top": 50,
                "right": 150,
                "bottom": 50,
            },  # Add padding for legend
        )
        .configure_view(stroke=None)
        .configure_axis(grid=True, gridOpacity=0.2)
        .configure_legend(
            orient="right",
            symbolSize=100,
            labelLimit=500,
            padding=10,
            offset=5,  # Move legend away from the chart
            titleFontSize=14,
            labelFontSize=12,
            strokeColor="gray",
            fillColor="#ffffff",
            cornerRadius=5,
            legendX=820,  # Position legend explicitly
            legendY=100,
        )
        .resolve_scale(
            color="independent"  # Make color scale independent of other scales
        )
    )

    # Save the chart to an HTML file
    if html_filename is None:
        html_filename = f"maest_{embedding_type}_embeddings_interactive.html"
    if output_dir is not None:
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, html_filename)
    else:
        output_path = html_filename

    chart.save(output_path)
    print(f"Interactive visualization saved to {output_path}")

    return output_path


def create_all_visualizations(embeddings_dir, output_dir=None):
    """
    Create visualizations for all embedding types.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files
        output_dir: Directory to save the HTML files

    Returns:
        List of paths to the saved HTML files
    """
    embedding_types = ["cls", "dist", "avg", "combined"]
    output_paths = []

    for embedding_type in embedding_types:
        print(f"\nCreating visualization for {embedding_type.upper()} embeddings...")
        output_path = create_visualization(
            embeddings_dir=embeddings_dir,
            embedding_type=embedding_type,
            output_dir=output_dir,
        )
        if output_path:
            output_paths.append(output_path)

    return output_paths


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Create interactive visualizations of MAEST audio embeddings"
    )
    parser.add_argument(
        "--embeddings_dir", default=None, help="Directory containing embedding files"
    )
    parser.add_argument(
        "--output_dir", default=None, help="Directory to save HTML files"
    )
    parser.add_argument(
        "--embedding_type",
        default="all",
        choices=["cls", "dist", "avg", "combined", "all"],
        help="Type of embedding to visualize",
    )

    args = parser.parse_args()

    # If embeddings_dir not specified, use default data/embeddings directory
    if args.embeddings_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # If output_dir not specified, use default data/visualizations directory
    if args.output_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        args.output_dir = os.path.join(project_dir, "data", "visualizations")

    # Create output directory if specified
    if args.output_dir:
        os.makedirs(args.output_dir, exist_ok=True)

    if args.embedding_type == "all":
        create_all_visualizations(args.embeddings_dir, args.output_dir)
    else:
        create_visualization(
            embeddings_dir=args.embeddings_dir,
            embedding_type=args.embedding_type,
            output_dir=args.output_dir,
        )
