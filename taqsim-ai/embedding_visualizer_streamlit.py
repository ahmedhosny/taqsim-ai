"""
Streamlit Embedding Visualizer for Taqsim AI

This module provides Streamlit components for visualizing audio embeddings
generated by the MAEST model. It integrates with the existing embedding
visualization pipeline but presents the results in a Streamlit interface.
"""

import glob
import os

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from umap import UMAP

# Global toggle for verbose info messages
SHOW_VERBOSE_INFO = False


def get_all_artists_from_csv():
    """
    Reads the metadata CSV and returns a sorted list of unique artist names.
    Handles potential missing 'artist' column or file errors.
    """
    # Path to the metadata CSV file - ensure this path is correct and accessible
    # Consider making this path configurable or relative to the project root if needed
    csv_path = "/Users/ahmedhosny/taqsim-ai/data/taqsim_ai.csv"
    try:
        df = pd.read_csv(csv_path)
        if "artist" in df.columns:
            # Get unique artists, convert to string, strip whitespace, handle empty strings, sort
            # Fill NaN and empty strings with a consistent placeholder first
            # Then convert to string, strip, and replace placeholder and 'nan' string with 'Unknown Artist'
            # 1. Convert 'artist' column to string type.
            series = df["artist"].astype(str)
            # 2. Convert to lowercase.
            series = series.str.lower()
            # 3. Strip whitespace from all entries.
            series = series.str.strip()
            # 4. Replace empty strings and the literal string 'nan' (which is now guaranteed lowercase)
            #    with a canonical lowercase 'unknown artist'.
            series = series.replace(["", "nan"], "unknown artist")
            # 5. Get unique, sorted list of artist names.
            artists = sorted(list(series.unique()))
            # Ensure "Unknown Artist" is treated as one category if it results from multiple sources (NaN, empty, 'nan')
            # The .unique() above should handle this, but let's be sure it's clean.
            # If "Unknown Artist" is the only thing and it's not desired, could filter here.
            return artists
        else:
            # Log to sidebar or main page depending on context if Streamlit elements are used here
            # For a pure helper, returning empty and letting caller handle st messages is cleaner
            # st.sidebar.warning("Metadata CSV is missing 'artist' column.")
            return []
    except FileNotFoundError:
        # st.sidebar.error(f"Metadata CSV file not found at: {csv_path}")
        return []


# Helper function to get all unique song names from the metadata CSV
def get_all_songs_from_csv():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    csv_path = os.path.join(project_dir, "data", "taqsim_ai.csv")
    try:
        df = pd.read_csv(csv_path)
        if "song_name" in df.columns:
            songs = sorted(
                list(
                    df["song_name"]
                    .astype(str)
                    .str.strip()
                    .replace("", "Unknown Song")
                    .fillna(
                        "Unknown Song"
                    )  # Note: fillna after astype(str) might not catch all original NaNs if they became 'nan' string
                    .unique()
                )
            )
            return songs
        else:
            return []
    except FileNotFoundError:
        return []
    except Exception:
        # st.sidebar.error(f"Error reading songs from CSV: {e}") # Consider context for st messages
        return []


# Helper function to get all unique maqam names from the metadata CSV
def get_all_maqams_from_csv():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    csv_path = os.path.join(project_dir, "data", "taqsim_ai.csv")
    try:
        df = pd.read_csv(csv_path)
        if "maqam" in df.columns:
            maqams = sorted(
                list(
                    df["maqam"]
                    .astype(str)
                    .str.strip()
                    .replace("", "Unknown Maqam")
                    .fillna("Unknown Maqam")
                    .unique()
                )
            )
            return maqams
        else:
            return []
    except FileNotFoundError:
        return []
    except Exception:
        # st.sidebar.error(f"Error reading maqams from CSV: {e}") # Consider context for st messages
        return []
    except Exception as _e:
        # st.sidebar.error(f"Error reading artists from CSV: {_e}")
        return []


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.
    Works with the structure where each chunk has its own NPZ file.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}
    failed_files = []  # Initialize list to store names of files that failed to load

    # Find all .npz files in the embeddings directory
    # The pattern is: {uuid}_{chunk_number}_{start_second}_{end_second}.npz
    embedding_files = glob.glob(os.path.join(embeddings_dir, "*.npz"))

    if not embedding_files:
        st.warning(f"No embedding files found in {embeddings_dir}")
        return all_embeddings

    if SHOW_VERBOSE_INFO:
        st.info(f"Found {len(embedding_files)} embedding files")

    for file_path in embedding_files:
        # Extract video ID and chunk number from filename
        basename = os.path.basename(file_path)
        base_name_no_ext = os.path.splitext(basename)[0]
        parts = base_name_no_ext.split("_")

        # Need at least 4 parts: uuid, chunk_number, start_second, end_second
        if len(parts) < 4:
            st.warning(f"Skipping file with invalid name format: {basename}")
            continue

        # The UUID is the first part
        video_id = parts[0]
        # The chunk number is the second part
        chunk_num = parts[1]
        chunk_key = f"chunk_{chunk_num}"

        # Load the embedding from the NPZ file
        try:
            embedding_data = np.load(file_path)
            # Check if the file contains the 'embedding' key
            if "embedding" in embedding_data:
                embedding = embedding_data["embedding"]
                # Initialize the dictionary for this video ID if it doesn't exist
                if video_id not in all_embeddings:
                    all_embeddings[video_id] = {}
                # Add the embedding for this chunk
                all_embeddings[video_id][chunk_key] = embedding
            else:
                st.warning(f"File {basename} does not contain 'embedding' key")
        except Exception as e:
            st.error(f"Error loading embedding from {basename}: {e}")
            failed_files.append(basename)

    # Print some statistics
    if SHOW_VERBOSE_INFO:
        st.info(
            f"Loaded {len(all_embeddings)} videos with embeddings. "
            f"{len(failed_files)} files failed to load."
        )

    return all_embeddings


def get_metadata_from_csv(video_ids):
    """
    Get metadata for the specified video IDs from the CSV file.

    Args:
        video_ids: List of video IDs to get metadata for

    Returns:
        Dictionary mapping video IDs to their metadata
    """
    metadata = {}

    # Path to the metadata CSV file
    csv_path = "/Users/ahmedhosny/taqsim-ai/data/taqsim_ai.csv"

    try:
        df = pd.read_csv(csv_path)

        if df.empty:
            st.warning("CSV file is empty")
            return metadata

        if "uuid" not in df.columns:
            st.warning("CSV file is missing 'uuid' column. Cannot match metadata.")
            return metadata

        # Count how many UUIDs match
        matched_count = 0

        for _, row in df.iterrows():
            try:
                if "uuid" in row:
                    uuid = str(row["uuid"])
                    if uuid in video_ids:
                        # Create a dictionary of metadata for this video
                        video_metadata = {}
                        for col in df.columns:
                            if col != "uuid":
                                video_metadata[col] = row[col]
                        metadata[uuid] = video_metadata
                        matched_count += 1
            except Exception as e:
                st.error(f"Error processing row in CSV: {e}")

        if SHOW_VERBOSE_INFO:
            st.info(f"Found metadata for {matched_count} out of {len(video_ids)} UUIDs")
    except Exception as e:
        st.error(f"Error reading CSV file: {e}")

    return metadata


def prepare_embeddings_for_umap(
    all_embeddings,
    embedding_type="cls",
    exclude_last_chunk=False,
    only_first_chunk=False,
):
    """
    Prepare embeddings for UMAP dimensionality reduction.
    Can optionally exclude the last chunk from each video or only include the first chunk.

    Args:
        all_embeddings: Dictionary of embeddings by video ID and chunk
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        only_first_chunk: If True, only include the first chunk from each video

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        # If we need to exclude the last chunk, find the maximum chunk number
        max_chunk = -1
        min_chunk = float("inf")
        if (exclude_last_chunk or only_first_chunk) and video_embeddings:
            chunk_numbers_list = [
                int(chunk_key.split("_")[1]) for chunk_key in video_embeddings.keys()
            ]
            if exclude_last_chunk:
                max_chunk = max(chunk_numbers_list)
            if only_first_chunk:
                min_chunk = min(chunk_numbers_list)

        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Skip this chunk if it's the last one and we're excluding last chunks
            if exclude_last_chunk and chunk_num == max_chunk:
                continue

            # Skip this chunk if it's not the first one and we're only including first chunks
            if only_first_chunk and chunk_num != min_chunk:
                continue

            # Check the shape of the embedding to determine its structure
            if len(embedding.shape) == 2 and embedding.shape[0] == 3:
                # Original format with [3, 768] shape where:
                # embedding[0] = CLS token embedding
                # embedding[1] = DIST token embedding
                # embedding[2] = Average of other token embeddings
                if embedding_type == "cls":
                    embeddings_list.append(embedding[0])
                elif embedding_type == "dist":
                    embeddings_list.append(embedding[1])
                elif embedding_type == "avg":
                    embeddings_list.append(embedding[2])
                elif embedding_type == "combined":
                    # Concatenate all three embeddings
                    embeddings_list.append(
                        np.concatenate([embedding[0], embedding[1], embedding[2]])
                    )
            else:
                # New format where the embedding is already a single vector
                embeddings_list.append(embedding)

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    # Convert to numpy arrays for UMAP
    if embeddings_list:
        embeddings_array = np.vstack(embeddings_list)
        return embeddings_array, video_ids_list, chunk_numbers
    else:
        st.warning("No valid embeddings found for the selected embedding type.")
        return np.array([]), [], []


def create_embedding_visualization(
    embeddings_dir: str,
    embedding_type: str = "cls",
    exclude_last_chunk: bool = False,
    artist_filter: list[str] | None = None,
    song_filter: list[str] | None = None,
    maqam_filter: list[str] | None = None,
    only_first_chunk: bool = False,
    color_selection: str = "artist",
    show_lines: bool = False,
    show_chunk_numbers: bool = False,
    show_only_selected_artist_labels: bool = False,
    debug: bool = False,
):
    """
    Create an interactive visualization of audio embeddings using Altair.

    Args:
        embeddings_dir: Directory containing embedding files
        embedding_type: Type of embedding to visualize ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        artist_filter: Optional list of artist names to filter by. If None or empty, no artist filter is applied.
        song_filter: Optional list of song names to filter by. If None or empty, no song filter is applied.
        only_first_chunk: If True, only include the first chunk from each video
        color_selection: Attribute to color points by (e.g., 'song_name', 'artist')
        help="Toggle whether to show connecting lines between segments of the same audio.",
    )
    show_chunk_numbers: Boolean to show chunk numbers on points
    show_only_selected_artist_labels: Boolean to only show labels for selected artists
    debug: Boolean to enable debug mode

    Returns:
        Altair chart object or None if visualization couldn't be created
    """

    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)
    if not all_embeddings:
        st.error("No embeddings found. Please check the embeddings directory.")
        return None

    # Prepare embeddings for UMAP
    embedding_array, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type, exclude_last_chunk, only_first_chunk
    )

    # Check if we have any embeddings to visualize
    if len(embedding_array) == 0:
        st.error(
            f"No embeddings found for type '{embedding_type}'. Try a different embedding type."
        )
        return None

    # Get metadata for all video IDs
    unique_video_ids = list(set(video_ids))
    metadata_by_video = get_metadata_from_csv(unique_video_ids)

    # Reduce dimensionality with UMAP
    with st.spinner(
        f"Reducing dimensionality with UMAP (embedding type: {embedding_type})..."
    ):
        reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
        embedding_2d = reducer.fit_transform(embedding_array)

    # Create a DataFrame for Altair with all metadata
    df_data = {
        "x": embedding_2d[:, 0],
        "y": embedding_2d[:, 1],
        "video_id": video_ids,
        "chunk_number": chunk_numbers,
    }

    # Create a mapping from each video_id to its metadata
    # This ensures consistent metadata for all chunks from the same video
    for column in [
        "song_name",
        "artist",
        "maqam",
        "type",
        "electric",
        "vintage",
        "link",
    ]:
        column_values = []
        for vid in video_ids:
            # Get metadata for this video ID
            metadata = metadata_by_video.get(vid, {})
            # Use lowercase 'unknown artist' as the standard for missing/invalid artist names
            default_value = "unknown artist" if column == "artist" else "Unknown"
            raw_value = metadata.get(column, default_value)

            if column == "artist":
                # 1. Convert to string type.
                processed_value = str(raw_value)
                # 2. Convert to lowercase.
                processed_value = processed_value.lower()
                # 3. Strip whitespace.
                processed_value = processed_value.strip()
                # 4. Replace empty strings and the literal string 'nan' (now guaranteed lowercase)
                #    with the canonical lowercase 'unknown artist'.
                if processed_value == "" or processed_value == "nan":
                    processed_value = "unknown artist"
                value = processed_value
            else:
                value = raw_value  # For other columns (including song_name), use the raw value or its generic default
            column_values.append(value)
        df_data[column] = column_values

    # Create the DataFrame
    df = pd.DataFrame(df_data)

    # Apply artist filter if provided and not empty
    if artist_filter and isinstance(artist_filter, list) and len(artist_filter) > 0:
        if SHOW_VERBOSE_INFO:
            st.info(f"Filtering by artists: {', '.join(artist_filter)}")
        total_points_before_artist_filter = len(df)
        unique_artists_before_artist_filter = df["artist"].nunique()
        df = df[df["artist"].isin(artist_filter)]
        filtered_points_after_artist_filter = len(df)
        unique_artists_after_artist_filter = df["artist"].nunique()

        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {total_points_before_artist_filter} points to {filtered_points_after_artist_filter} points based on artist selection."
            )
        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {unique_artists_before_artist_filter} artists to {unique_artists_after_artist_filter} artists based on artist selection."
            )
        if df.empty:
            st.warning(
                "No data points remaining after artist filtering. Please adjust your selection."
            )
            return None

    # Filter by song_name if song_filter is provided
    if song_filter and isinstance(song_filter, list) and len(song_filter) > 0:
        total_points_before_song_filter = len(df)
        unique_songs_before_song_filter = df["song_name"].nunique()
        if SHOW_VERBOSE_INFO:
            st.info(f"Applying song filter: {song_filter}")
        df = df[df["song_name"].isin(song_filter)]
        filtered_points_after_song_filter = len(df)
        unique_songs_after_song_filter = df["song_name"].nunique()

        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {total_points_before_song_filter} points to {filtered_points_after_song_filter} points based on song selection."
            )
        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {unique_songs_before_song_filter} songs to {unique_songs_after_song_filter} songs based on song selection."
            )
        if df.empty:
            st.warning(
                "No data points remaining after song filtering. Please adjust your selection."
            )
            return None

    # Filter by maqam if maqam_filter is provided
    if maqam_filter and isinstance(maqam_filter, list) and len(maqam_filter) > 0:
        total_points_before_maqam_filter = len(df)
        unique_maqams_before_maqam_filter = df["maqam"].nunique()
        if SHOW_VERBOSE_INFO:
            st.info(f"Applying maqam filter: {maqam_filter}")
        df = df[df["maqam"].isin(maqam_filter)]
        filtered_points_after_maqam_filter = len(df)
        unique_maqams_after_maqam_filter = df["maqam"].nunique()

        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {total_points_before_maqam_filter} points to {filtered_points_after_maqam_filter} points based on maqam selection."
            )
        if SHOW_VERBOSE_INFO:
            st.info(
                f"Filtered from {unique_maqams_before_maqam_filter} maqams to {unique_maqams_after_maqam_filter} maqams based on maqam selection."
            )
        if df.empty:
            st.warning(
                "No data points remaining after maqam filtering. Please adjust your selection."
            )
            return None

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Base chart
    base = alt.Chart(df).encode(
        x=alt.X(
            "x:Q",
            title=None,
            axis=alt.Axis(labels=False, ticks=False, domain=False, grid=True),
        ),
        y=alt.Y(
            "y:Q",
            title=None,
            axis=alt.Axis(labels=False, ticks=False, domain=False, grid=True),
        ),
    )

    # Create lines between consecutive chunks
    lines_data = []
    if show_lines:
        for vid in df["video_id"].unique():
            vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
            if len(vid_df) > 1:
                for i in range(len(vid_df) - 1):
                    line_data = {
                        "x1": vid_df.iloc[i]["x"],
                        "y1": vid_df.iloc[i]["y"],
                        "x2": vid_df.iloc[i + 1]["x"],
                        "y2": vid_df.iloc[i + 1]["y"],
                    }
                    # Add all metadata columns
                    for col in [
                        "song_name",
                        "artist",
                        "maqam",
                        "type",
                        "electric",
                        "vintage",
                        "link",
                    ]:
                        line_data[col] = vid_df.iloc[i][col]
                    lines_data.append(line_data)

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data) if lines_data else pd.DataFrame()

    # Create the lines layer if we have line data

    # Create a selection that chooses the legend item for interactive opacity
    legend_selection = alt.selection_multi(fields=[color_selection], bind="legend")
    lines = None
    if not lines_df.empty and show_lines:
        lines = (
            alt.Chart(lines_df)
            .mark_line(strokeWidth=1.5)  # Original strokeWidth, dynamic opacity
            .encode(
                x="x1:Q",
                y="y1:Q",
                x2="x2:Q",
                y2="y2:Q",
                color=alt.Color(
                    f"{color_selection}:N",
                    legend=None,  # Hide legend for lines
                ),
                opacity=alt.condition(
                    legend_selection, alt.value(0.7), alt.value(0.1)
                ),  # Conditional opacity for lines
            )
            .add_selection(legend_selection)
        )

    # Create the points layer
    points = (
        base.mark_circle(size=100)
        .encode(
            color=alt.Color(
                f"{color_selection}:N",
                legend=alt.Legend(
                    title=color_selection.replace("_", " ").title(),
                ),
            ),
            tooltip=[
                "video_id:N",  # For UUID
                "song_name:N",
                "artist:N",
                "maqam:N",
                "type:N",  # Restored
                "electric:N",  # Restored
                "vintage:N",
                "chunk_number:Q",
                "link:N",
            ],
            opacity=alt.condition(legend_selection, alt.value(1.0), alt.value(0.05)),
        )
        .add_selection(legend_selection)
    )

    # Create the text layer for chunk numbers if requested
    text = None
    if show_chunk_numbers:
        text = (
            base.mark_text(align="center", baseline="middle", dy=-10, fontSize=10)
            .encode(
                text="chunk_number:N",
                color=alt.value("black"),
                opacity=alt.condition(legend_selection, alt.value(1.0), alt.value(0.2)),
            )
            .add_selection(legend_selection)
        )

    # Combine the layers
    layers = [points]
    if lines is not None:
        layers.append(lines)
    if text is not None:
        layers.append(text)

    # Create the final chart
    chart = (
        alt.layer(*layers)
        .properties(
            width=900,
            height=1000,
            title=f"MAEST Audio Embeddings - {embedding_type.upper()} Tokens",
            padding={"left": 0, "top": 0, "right": 0, "bottom": 0},
        )
        .resolve_legend(color="independent")
        .configure_legend(
            orient="right",
            labelLimit=75,
            symbolLimit=0,
            columns=3,
        )
        .interactive()
    )

    return chart


# Callback for multiselect artist filter
def callback_multiselect_artists():
    # This callback is for the multiselect widget
    # It reads the multiselect's current selection (which triggered the callback)
    # and updates the main selected_artists_for_filter list.
    st.session_state.selected_artists_for_filter = st.session_state.get(
        "multiselect_artist_value", []
    )[:]


# Callback for multiselect song filter
def callback_multiselect_songs():
    st.session_state.selected_songs_for_filter = st.session_state.get(
        "multiselect_song_value", []
    )[:]


# Callback for multiselect maqam filter
def callback_multiselect_maqams():
    st.session_state.selected_maqams_for_filter = st.session_state.get(
        "multiselect_maqam_value", []
    )[:]


def embedding_visualizer_ui():
    """
    Streamlit UI for the embedding visualizer
    """
    global SHOW_VERBOSE_INFO

    # Initialize session state for the verbose info checkbox if it's not already set.
    # This ensures that on the first run of a new session, it takes the global default (False).
    # The global SHOW_VERBOSE_INFO (defined at the top of the script) is used as this default.
    if "show_verbose_info_checkbox_val" not in st.session_state:
        st.session_state.show_verbose_info_checkbox_val = (
            SHOW_VERBOSE_INFO  # Uses the global SHOW_VERBOSE_INFO
        )

    # Synchronize the function-scoped SHOW_VERBOSE_INFO with the session state.
    # On a fresh session, this will be the default. On refreshes, it will be the persisted value.
    SHOW_VERBOSE_INFO = st.session_state.show_verbose_info_checkbox_val

    # Get the project directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)

    # Set default embeddings directory
    default_embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # Sidebar for configuration
    st.sidebar.markdown("## Visualization Settings")

    # Embeddings directory input
    embeddings_dir = st.sidebar.text_input(
        "Embeddings Directory", value=default_embeddings_dir
    )

    # Embedding type selection
    embedding_type = st.sidebar.selectbox(
        "Embedding Type",
        ["cls", "dist", "avg", "combined"],
        index=3,
    )

    # Artist Filter Section
    current_artist_options = get_all_artists_from_csv()
    if "multiselect_artist_value" not in st.session_state:
        st.session_state.multiselect_artist_value = current_artist_options[:]
    else:
        st.session_state.multiselect_artist_value = [
            artist
            for artist in st.session_state.multiselect_artist_value
            if artist in current_artist_options
        ]
        if not current_artist_options:
            st.session_state.multiselect_artist_value = []
    if "selected_artists_for_filter" not in st.session_state:
        st.session_state.selected_artists_for_filter = (
            st.session_state.multiselect_artist_value[:]
        )
    if not current_artist_options:
        st.sidebar.warning("No artists found in metadata to filter by.")
        artist_filter_for_visualization = []
    else:
        with st.sidebar.expander("Filter by Artist", expanded=False):
            st.multiselect(
                "",
                options=current_artist_options,
                key="multiselect_artist_value",
                on_change=callback_multiselect_artists,
            )
    artist_filter_for_visualization = st.session_state.get(
        "selected_artists_for_filter", []
    )

    # --- Song Filter Section ---
    current_song_options = get_all_songs_from_csv()
    if "multiselect_song_value" not in st.session_state:
        st.session_state.multiselect_song_value = current_song_options[:]
    else:
        st.session_state.multiselect_song_value = [
            song
            for song in st.session_state.multiselect_song_value
            if song in current_song_options
        ]
        if not current_song_options:
            st.session_state.multiselect_song_value = []
    if "selected_songs_for_filter" not in st.session_state:
        st.session_state.selected_songs_for_filter = (
            st.session_state.multiselect_song_value[:]
        )
    st.session_state.selected_songs_for_filter = (
        st.session_state.multiselect_song_value[:]
    )
    if not current_song_options:
        st.sidebar.warning("No songs found in metadata to filter by.")
        song_filter_for_visualization = []
    else:
        with st.sidebar.expander("Filter by Taqsim", expanded=False):
            st.multiselect(
                "",
                options=current_song_options,
                key="multiselect_song_value",
                on_change=callback_multiselect_songs,
            )
    song_filter_for_visualization = st.session_state.get(
        "selected_songs_for_filter", []
    )

    # --- Maqam Filter Section ---
    current_maqam_options = get_all_maqams_from_csv()
    if "multiselect_maqam_value" not in st.session_state:
        st.session_state.multiselect_maqam_value = current_maqam_options[:]
    else:
        st.session_state.multiselect_maqam_value = [
            maqam
            for maqam in st.session_state.multiselect_maqam_value
            if maqam in current_maqam_options
        ]
        if not current_maqam_options:
            st.session_state.multiselect_maqam_value = []
    if "selected_maqams_for_filter" not in st.session_state:
        st.session_state.selected_maqams_for_filter = (
            st.session_state.multiselect_maqam_value[:]
        )
    st.session_state.selected_maqams_for_filter = (
        st.session_state.multiselect_maqam_value[:]
    )
    if not current_maqam_options:
        st.sidebar.warning("No maqams found in metadata to filter by.")
        maqam_filter_for_visualization = []
    else:
        with st.sidebar.expander("Filter by Maqam", expanded=False):
            st.multiselect(
                "",
                options=current_maqam_options,
                key="multiselect_maqam_value",
                on_change=callback_multiselect_maqams,
            )
    maqam_filter_for_visualization = st.session_state.get(
        "selected_maqams_for_filter", []
    )

    # Chunk filtering options
    exclude_last_chunk = st.sidebar.checkbox(
        "Exclude Last Segment",
        value=True,
    )
    only_first_chunk = st.sidebar.checkbox(
        "Only First Segment",
        value=False,
    )

    st.sidebar.markdown("---")  # Separator
    st.sidebar.subheader("Chart Appearance")

    color_selection = st.sidebar.selectbox(
        "Color by:",
        ["song_name", "artist", "maqam", "type", "electric", "vintage"],
        index=0,
    )
    show_lines = st.sidebar.checkbox("Show connecting lines", value=True)
    show_chunk_numbers = st.sidebar.checkbox("Show Segment Numbers", value=True)

    st.sidebar.markdown("---")  # Separator

    # Checkbox to control the global SHOW_VERBOSE_INFO variable.
    # Set its 'value' directly from SHOW_VERBOSE_INFO (which is False at this point on a refresh).
    # The 'key' allows Streamlit to manage its state in st.session_state upon interaction.
    st.sidebar.checkbox(
        "Show Detailed Info Messages",
        key="show_verbose_info_checkbox_val",  # Session state (initialized above or persisted) drives the value
    )

    # After the checkbox widget, update SHOW_VERBOSE_INFO from session state.
    # This ensures that if the user interacted with the checkbox, that state is used
    # for the rest of this script run.
    SHOW_VERBOSE_INFO = st.session_state.show_verbose_info_checkbox_val

    # Create a placeholder for the visualization
    chart_placeholder = st.empty()

    # Automatically generate visualization based on current settings
    if not os.path.exists(embeddings_dir):
        st.error(f"Embeddings directory does not exist: {embeddings_dir}")
    else:
        with st.spinner("Generating visualization..."):
            chart = create_embedding_visualization(
                embeddings_dir=embeddings_dir,
                embedding_type=embedding_type,
                exclude_last_chunk=exclude_last_chunk,
                artist_filter=artist_filter_for_visualization,
                song_filter=song_filter_for_visualization,
                maqam_filter=maqam_filter_for_visualization,
                only_first_chunk=only_first_chunk,
                color_selection=color_selection,
                show_lines=show_lines,
                show_chunk_numbers=show_chunk_numbers,
            )

            if chart:
                chart_placeholder.altair_chart(chart, use_container_width=True)


if __name__ == "__main__":
    embedding_visualizer_ui()
