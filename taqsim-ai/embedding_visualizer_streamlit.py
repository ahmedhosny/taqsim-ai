"""
Streamlit Embedding Visualizer for Taqsim AI

This module provides Streamlit components for visualizing audio embeddings
generated by the MAEST model. It integrates with the existing embedding
visualization pipeline but presents the results in a Streamlit interface.
"""

import glob
import os

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from umap import UMAP


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.
    Works with the structure where each chunk has its own NPZ file.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}

    # Find all .npz files in the embeddings directory
    # The pattern is: {uuid}_{chunk_number}_{start_second}_{end_second}.npz
    embedding_files = glob.glob(os.path.join(embeddings_dir, "*.npz"))

    if not embedding_files:
        st.warning(f"No embedding files found in {embeddings_dir}")
        return all_embeddings

    st.info(f"Found {len(embedding_files)} embedding files")

    for file_path in embedding_files:
        # Extract video ID and chunk number from filename
        basename = os.path.basename(file_path)
        base_name_no_ext = os.path.splitext(basename)[0]
        parts = base_name_no_ext.split("_")

        # Need at least 4 parts: uuid, chunk_number, start_second, end_second
        if len(parts) < 4:
            st.warning(f"Skipping file with invalid name format: {basename}")
            continue

        # The UUID is the first part
        video_id = parts[0]
        # The chunk number is the second part
        chunk_num = parts[1]
        chunk_key = f"chunk_{chunk_num}"

        # Load the embedding from the NPZ file
        try:
            embedding_data = np.load(file_path)
            # Check if the file contains the 'embedding' key
            if "embedding" in embedding_data:
                embedding = embedding_data["embedding"]
                # Initialize the dictionary for this video ID if it doesn't exist
                if video_id not in all_embeddings:
                    all_embeddings[video_id] = {}
                # Add the embedding for this chunk
                all_embeddings[video_id][chunk_key] = embedding
            else:
                st.warning(f"File {basename} does not contain 'embedding' key")
        except Exception as e:
            st.error(f"Error loading embedding from {basename}: {e}")

    # Print some statistics
    num_videos = len(all_embeddings)
    total_chunks = sum(len(chunks) for chunks in all_embeddings.values())
    st.info(
        f"Loaded embeddings for {num_videos} videos with {total_chunks} total chunks"
    )

    return all_embeddings


def get_metadata_from_csv(video_ids):
    """
    Get metadata for the specified video IDs from the CSV file.

    Args:
        video_ids: List of video IDs to get metadata for

    Returns:
        Dictionary mapping video IDs to their metadata
    """
    metadata = {}

    # Path to the metadata CSV file
    csv_path = "/Users/ahmedhosny/taqsim-ai/data/taqsim_ai.csv"

    try:
        df = pd.read_csv(csv_path)

        if df.empty:
            st.warning("CSV file is empty")
            return metadata

        if "uuid" not in df.columns:
            st.warning("CSV file is missing 'uuid' column. Cannot match metadata.")
            return metadata

        # Count how many UUIDs match
        matched_count = 0

        for _, row in df.iterrows():
            try:
                if "uuid" in row:
                    uuid = str(row["uuid"])
                    if uuid in video_ids:
                        # Create a dictionary of metadata for this video
                        video_metadata = {}
                        for col in df.columns:
                            if col != "uuid":
                                video_metadata[col] = row[col]
                        metadata[uuid] = video_metadata
                        matched_count += 1
            except Exception as e:
                st.error(f"Error processing row in CSV: {e}")

        st.info(f"Found metadata for {matched_count} out of {len(video_ids)} UUIDs")
    except Exception as e:
        st.error(f"Error reading CSV file: {e}")

    return metadata


def prepare_embeddings_for_umap(
    all_embeddings,
    embedding_type="cls",
    exclude_last_chunk=False,
    only_first_chunk=False,
):
    """
    Prepare embeddings for UMAP dimensionality reduction.
    Can optionally exclude the last chunk from each video or only include the first chunk.

    Args:
        all_embeddings: Dictionary of embeddings by video ID and chunk
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        only_first_chunk: If True, only include the first chunk from each video

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        # If we need to exclude the last chunk, find the maximum chunk number
        max_chunk = -1
        min_chunk = float("inf")
        if (exclude_last_chunk or only_first_chunk) and video_embeddings:
            chunk_numbers_list = [
                int(chunk_key.split("_")[1]) for chunk_key in video_embeddings.keys()
            ]
            if exclude_last_chunk:
                max_chunk = max(chunk_numbers_list)
            if only_first_chunk:
                min_chunk = min(chunk_numbers_list)

        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Skip this chunk if it's the last one and we're excluding last chunks
            if exclude_last_chunk and chunk_num == max_chunk:
                continue

            # Skip this chunk if it's not the first one and we're only including first chunks
            if only_first_chunk and chunk_num != min_chunk:
                continue

            # Check the shape of the embedding to determine its structure
            if len(embedding.shape) == 2 and embedding.shape[0] == 3:
                # Original format with [3, 768] shape where:
                # embedding[0] = CLS token embedding
                # embedding[1] = DIST token embedding
                # embedding[2] = Average of other token embeddings
                if embedding_type == "cls":
                    embeddings_list.append(embedding[0])
                elif embedding_type == "dist":
                    embeddings_list.append(embedding[1])
                elif embedding_type == "avg":
                    embeddings_list.append(embedding[2])
                elif embedding_type == "combined":
                    # Concatenate all three embeddings
                    embeddings_list.append(
                        np.concatenate([embedding[0], embedding[1], embedding[2]])
                    )
            else:
                # New format where the embedding is already a single vector
                embeddings_list.append(embedding)

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    # Convert to numpy arrays for UMAP
    if embeddings_list:
        embeddings_array = np.vstack(embeddings_list)
        return embeddings_array, video_ids_list, chunk_numbers
    else:
        st.warning("No valid embeddings found for the selected embedding type.")
        return np.array([]), [], []


def create_embedding_visualization(
    embeddings_dir,
    embedding_type="cls",
    exclude_last_chunk=False,
    artist_filter=None,
    only_first_chunk=False,
    color_selection="song_name",
    show_lines=True,
    show_numbers=True,
):
    """
    Create an interactive visualization of audio embeddings using Altair.

    Args:
        embeddings_dir: Directory containing embedding files
        embedding_type: Type of embedding to visualize ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        artist_filter: If provided, only include songs by this artist
        only_first_chunk: If True, only include the first chunk from each video
        color_selection: Attribute to color points by (e.g., 'song_name', 'artist')
        show_lines: Boolean to show connecting lines between chunks
        show_numbers: Boolean to show chunk numbers on points

    Returns:
        Altair chart object or None if visualization couldn't be created
    """
    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)
    if not all_embeddings:
        st.error("No embeddings found. Please check the embeddings directory.")
        return None

    # Prepare embeddings for UMAP
    embedding_array, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type, exclude_last_chunk, only_first_chunk
    )

    # Check if we have any embeddings to visualize
    if len(embedding_array) == 0:
        st.error(
            f"No embeddings found for type '{embedding_type}'. Try a different embedding type."
        )
        return None

    # Get metadata for all video IDs
    unique_video_ids = list(set(video_ids))
    metadata_by_video = get_metadata_from_csv(unique_video_ids)

    # Reduce dimensionality with UMAP
    with st.spinner(
        f"Reducing dimensionality with UMAP (embedding type: {embedding_type})..."
    ):
        reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
        embedding_2d = reducer.fit_transform(embedding_array)

    # Create a DataFrame for Altair with all metadata
    df_data = {
        "x": embedding_2d[:, 0],
        "y": embedding_2d[:, 1],
        "video_id": video_ids,
        "chunk_number": chunk_numbers,
    }

    # Create a mapping from each video_id to its metadata
    # This ensures consistent metadata for all chunks from the same video
    for column in [
        "song_name",
        "artist",
        "maqam",
        "type",
        "electric",
        "vintage",
        "link",
    ]:
        column_values = []
        for vid in video_ids:
            # Get metadata for this video ID
            metadata = metadata_by_video.get(vid, {})
            value = metadata.get(column, "Unknown")
            column_values.append(value)
        df_data[column] = column_values

    # Create the DataFrame
    df = pd.DataFrame(df_data)

    # Apply artist filter if specified
    if artist_filter:
        st.info(f"Filtering to only include songs by artist: {artist_filter}")
        # Count before filtering
        total_points = len(df)
        unique_songs_before = df["song_name"].nunique()

        # Apply filter (case insensitive)
        df = df[df["artist"].str.lower() == artist_filter.lower()]

        # Count after filtering
        filtered_points = len(df)
        unique_songs_after = df["song_name"].nunique()

        st.info(f"Filtered from {total_points} points to {filtered_points} points")
        st.info(
            f"Filtered from {unique_songs_before} songs to {unique_songs_after} songs"
        )

        if filtered_points == 0:
            st.warning(
                f"No data points remain after filtering for artist '{artist_filter}'"
            )
            st.write("Available artists in the dataset:")
            available_artists = df_data["artist"]
            unique_artists = set(available_artists)
            for artist in sorted(unique_artists):
                st.write(f"  - {artist}")
            return None

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Base chart
    base = alt.Chart(df).encode(
        x=alt.X("x:Q", title="UMAP Dimension 1"),
        y=alt.Y("y:Q", title="UMAP Dimension 2"),
    )

    # Create lines between consecutive chunks
    lines_data = []
    if show_lines:
        for vid in df["video_id"].unique():
            vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
            if len(vid_df) > 1:
                for i in range(len(vid_df) - 1):
                    line_data = {
                        "x1": vid_df.iloc[i]["x"],
                        "y1": vid_df.iloc[i]["y"],
                        "x2": vid_df.iloc[i + 1]["x"],
                        "y2": vid_df.iloc[i + 1]["y"],
                    }
                    # Add all metadata columns
                    for col in [
                        "song_name",
                        "artist",
                        "maqam",
                        "type",
                        "electric",
                        "vintage",
                        "link",
                    ]:
                        line_data[col] = vid_df.iloc[i][col]
                    lines_data.append(line_data)

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data) if lines_data else pd.DataFrame()

    # Create the lines layer if we have line data
    lines = None
    if not lines_df.empty and show_lines:
        lines = (
            alt.Chart(lines_df)
            .mark_line(opacity=0.5, strokeWidth=1.5)
            .encode(
                x="x1:Q",
                y="y1:Q",
                x2="x2:Q",
                y2="y2:Q",
                color=alt.Color(
                    f"{color_selection}:N",
                    legend=None,
                ),
                tooltip=[
                    "song_name:N",
                    "artist:N",
                    "maqam:N",
                    "type:N",
                    "electric:N",
                    "vintage:N",
                ],
            )
        )

    # Create the points layer
    points = base.mark_circle(size=100).encode(
        color=alt.Color(
            f"{color_selection}:N",
            legend=alt.Legend(title=color_selection.replace("_", " ").title()),
        ),
        tooltip=[
            "song_name:N",
            "artist:N",
            "maqam:N",
            "type:N",
            "electric:N",
            "vintage:N",
            "chunk_number:Q",
            "link:N",
        ],
    )

    # Create the text layer for chunk numbers if requested
    text = None
    if show_numbers:
        text = base.mark_text(
            align="center", baseline="middle", dy=-10, fontSize=10
        ).encode(
            text="chunk_number:N",
            color=alt.value("black"),
        )

    # Combine the layers
    layers = [points]
    if lines is not None:
        layers.append(lines)
    if text is not None:
        layers.append(text)

    # Create the final chart
    chart = (
        alt.layer(*layers)
        .properties(
            width=700,
            height=500,
            title=f"MAEST Audio Embeddings - {embedding_type.upper()} Tokens",
        )
        .interactive()
    )

    return chart


def embedding_visualizer_ui():
    """
    Streamlit UI for the embedding visualizer
    """

    # Get the project directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)

    # Set default embeddings directory
    default_embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # Sidebar for configuration
    st.sidebar.header("Visualization Settings")

    # Embeddings directory input
    embeddings_dir = st.sidebar.text_input(
        "Embeddings Directory", value=default_embeddings_dir
    )

    # Embedding type selection
    embedding_type = st.sidebar.selectbox(
        "Embedding Type",
        ["cls", "dist", "avg", "combined"],
        index=0,
        help="Type of embedding to visualize",
    )

    # Artist filter
    artist_filter = st.sidebar.text_input(
        "Filter by Artist",
        value="",
        help="Only include songs by this artist (case insensitive)",
    )

    # Chunk filtering options
    exclude_last_chunk = st.sidebar.checkbox(
        "Exclude Last Chunk", value=False, help="Exclude the last chunk from each song"
    )

    only_first_chunk = st.sidebar.checkbox(
        "Only First Chunk",
        value=False,
        help="Only include the first chunk from each song",
    )

    st.sidebar.markdown("---")  # Separator
    st.sidebar.subheader("Chart Appearance")

    # Color by selection
    color_selection = st.sidebar.selectbox(
        "Color by:",
        ["song_name", "artist", "maqam", "type", "electric", "vintage"],
        index=0,
        help="Attribute to color points by",
    )

    # Toggle for showing connecting lines
    show_lines = st.sidebar.checkbox("Show connecting lines", value=True)

    # Toggle for showing chunk numbers
    show_numbers = st.sidebar.checkbox("Show chunk numbers", value=True)

    # Create a placeholder for the visualization
    chart_placeholder = st.empty()

    # Automatically generate visualization based on current settings
    if not os.path.exists(embeddings_dir):
        st.error(f"Embeddings directory does not exist: {embeddings_dir}")
    else:
        with st.spinner("Generating visualization..."):
            chart = create_embedding_visualization(
                embeddings_dir=embeddings_dir,
                embedding_type=embedding_type,
                exclude_last_chunk=exclude_last_chunk,
                artist_filter=artist_filter if artist_filter else None,
                only_first_chunk=only_first_chunk,
                color_selection=color_selection,
                show_lines=show_lines,
                show_numbers=show_numbers,
            )

            if chart:
                # Display the chart in the placeholder
                chart_placeholder.altair_chart(chart, use_container_width=True)

                # Download button has been removed as per user request.


if __name__ == "__main__":
    embedding_visualizer_ui()
