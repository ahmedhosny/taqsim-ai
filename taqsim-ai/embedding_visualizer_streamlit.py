"""
Streamlit Embedding Visualizer for Taqsim AI

This module provides Streamlit components for visualizing audio embeddings
generated by the MAEST model. It integrates with the existing embedding
visualization pipeline but presents the results in a Streamlit interface.
"""

import glob
import os

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from umap import UMAP


def get_all_artists_from_csv():
    """
    Reads the metadata CSV and returns a sorted list of unique artist names.
    Handles potential missing 'artist' column or file errors.
    """
    # Path to the metadata CSV file - ensure this path is correct and accessible
    # Consider making this path configurable or relative to the project root if needed
    csv_path = "/Users/ahmedhosny/taqsim-ai/data/taqsim_ai.csv"
    try:
        df = pd.read_csv(csv_path)
        if "artist" in df.columns:
            # Get unique artists, convert to string, strip whitespace, handle empty strings, sort
            artists = sorted(list(
                df["artist"].astype(str).str.strip().replace('', 'Unknown Artist').fillna('Unknown Artist').unique()
            ))
            # Remove 'Unknown Artist' if it's only there due to empty strings and not a real entry, if desired
            # For now, it will be included if present.
            return artists
        else:
            # Log to sidebar or main page depending on context if Streamlit elements are used here
            # For a pure helper, returning empty and letting caller handle st messages is cleaner
            # st.sidebar.warning("Metadata CSV is missing 'artist' column.") 
            return []
    except FileNotFoundError:
        # st.sidebar.error(f"Metadata CSV file not found at: {csv_path}")
        return []
    except Exception as _e:
        # st.sidebar.error(f"Error reading artists from CSV: {_e}")
        return []


def load_embeddings(embeddings_dir):
    """
    Load all embedding files from the specified directory.
    Works with the structure where each chunk has its own NPZ file.

    Args:
        embeddings_dir: Path to the directory containing embedding .npz files

    Returns:
        Dictionary with video IDs as keys and dictionaries of chunk embeddings as values
    """
    all_embeddings = {}

    # Find all .npz files in the embeddings directory
    # The pattern is: {uuid}_{chunk_number}_{start_second}_{end_second}.npz
    embedding_files = glob.glob(os.path.join(embeddings_dir, "*.npz"))

    if not embedding_files:
        st.warning(f"No embedding files found in {embeddings_dir}")
        return all_embeddings

    st.info(f"Found {len(embedding_files)} embedding files")

    for file_path in embedding_files:
        # Extract video ID and chunk number from filename
        basename = os.path.basename(file_path)
        base_name_no_ext = os.path.splitext(basename)[0]
        parts = base_name_no_ext.split("_")

        # Need at least 4 parts: uuid, chunk_number, start_second, end_second
        if len(parts) < 4:
            st.warning(f"Skipping file with invalid name format: {basename}")
            continue

        # The UUID is the first part
        video_id = parts[0]
        # The chunk number is the second part
        chunk_num = parts[1]
        chunk_key = f"chunk_{chunk_num}"

        # Load the embedding from the NPZ file
        try:
            embedding_data = np.load(file_path)
            # Check if the file contains the 'embedding' key
            if "embedding" in embedding_data:
                embedding = embedding_data["embedding"]
                # Initialize the dictionary for this video ID if it doesn't exist
                if video_id not in all_embeddings:
                    all_embeddings[video_id] = {}
                # Add the embedding for this chunk
                all_embeddings[video_id][chunk_key] = embedding
            else:
                st.warning(f"File {basename} does not contain 'embedding' key")
        except Exception as e:
            st.error(f"Error loading embedding from {basename}: {e}")

    # Print some statistics
    num_videos = len(all_embeddings)
    total_chunks = sum(len(chunks) for chunks in all_embeddings.values())
    st.info(
        f"Loaded embeddings for {num_videos} videos with {total_chunks} total chunks"
    )

    return all_embeddings


def get_metadata_from_csv(video_ids):
    """
    Get metadata for the specified video IDs from the CSV file.

    Args:
        video_ids: List of video IDs to get metadata for

    Returns:
        Dictionary mapping video IDs to their metadata
    """
    metadata = {}

    # Path to the metadata CSV file
    csv_path = "/Users/ahmedhosny/taqsim-ai/data/taqsim_ai.csv"

    try:
        df = pd.read_csv(csv_path)

        if df.empty:
            st.warning("CSV file is empty")
            return metadata

        if "uuid" not in df.columns:
            st.warning("CSV file is missing 'uuid' column. Cannot match metadata.")
            return metadata

        # Count how many UUIDs match
        matched_count = 0

        for _, row in df.iterrows():
            try:
                if "uuid" in row:
                    uuid = str(row["uuid"])
                    if uuid in video_ids:
                        # Create a dictionary of metadata for this video
                        video_metadata = {}
                        for col in df.columns:
                            if col != "uuid":
                                video_metadata[col] = row[col]
                        metadata[uuid] = video_metadata
                        matched_count += 1
            except Exception as e:
                st.error(f"Error processing row in CSV: {e}")

        st.info(f"Found metadata for {matched_count} out of {len(video_ids)} UUIDs")
    except Exception as e:
        st.error(f"Error reading CSV file: {e}")

    return metadata


def prepare_embeddings_for_umap(
    all_embeddings,
    embedding_type="cls",
    exclude_last_chunk=False,
    only_first_chunk=False,
):
    """
    Prepare embeddings for UMAP dimensionality reduction.
    Can optionally exclude the last chunk from each video or only include the first chunk.

    Args:
        all_embeddings: Dictionary of embeddings by video ID and chunk
        embedding_type: Which embedding type to use ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        only_first_chunk: If True, only include the first chunk from each video

    Returns:
        Tuple of (embeddings array, video_ids list, chunk_numbers list)
    """
    embeddings_list = []
    video_ids_list = []
    chunk_numbers = []

    for video_id, video_embeddings in all_embeddings.items():
        # If we need to exclude the last chunk, find the maximum chunk number
        max_chunk = -1
        min_chunk = float("inf")
        if (exclude_last_chunk or only_first_chunk) and video_embeddings:
            chunk_numbers_list = [
                int(chunk_key.split("_")[1]) for chunk_key in video_embeddings.keys()
            ]
            if exclude_last_chunk:
                max_chunk = max(chunk_numbers_list)
            if only_first_chunk:
                min_chunk = min(chunk_numbers_list)

        for chunk_key, embedding in video_embeddings.items():
            # Extract chunk number from key (e.g., 'chunk_1' -> 1)
            chunk_num = int(chunk_key.split("_")[1])

            # Skip this chunk if it's the last one and we're excluding last chunks
            if exclude_last_chunk and chunk_num == max_chunk:
                continue

            # Skip this chunk if it's not the first one and we're only including first chunks
            if only_first_chunk and chunk_num != min_chunk:
                continue

            # Check the shape of the embedding to determine its structure
            if len(embedding.shape) == 2 and embedding.shape[0] == 3:
                # Original format with [3, 768] shape where:
                # embedding[0] = CLS token embedding
                # embedding[1] = DIST token embedding
                # embedding[2] = Average of other token embeddings
                if embedding_type == "cls":
                    embeddings_list.append(embedding[0])
                elif embedding_type == "dist":
                    embeddings_list.append(embedding[1])
                elif embedding_type == "avg":
                    embeddings_list.append(embedding[2])
                elif embedding_type == "combined":
                    # Concatenate all three embeddings
                    embeddings_list.append(
                        np.concatenate([embedding[0], embedding[1], embedding[2]])
                    )
            else:
                # New format where the embedding is already a single vector
                embeddings_list.append(embedding)

            video_ids_list.append(video_id)
            chunk_numbers.append(chunk_num)

    # Convert to numpy arrays for UMAP
    if embeddings_list:
        embeddings_array = np.vstack(embeddings_list)
        return embeddings_array, video_ids_list, chunk_numbers
    else:
        st.warning("No valid embeddings found for the selected embedding type.")
        return np.array([]), [], []


def create_embedding_visualization(
    embeddings_dir,
    embedding_type="cls",
    exclude_last_chunk=False,
    artist_filter: list[str] | None = None,  # Expect a list of artists or None
    only_first_chunk=False,
    color_selection="song_name",
    show_lines=True,
    show_numbers=True,
):
    """
    Create an interactive visualization of audio embeddings using Altair.

    Args:
        embeddings_dir: Directory containing embedding files
        embedding_type: Type of embedding to visualize ('cls', 'dist', 'avg', or 'combined')
        exclude_last_chunk: If True, exclude the last chunk from each video
        artist_filter: Optional list of artist names to filter by. If None or empty, no artist filter is applied.
        only_first_chunk: If True, only include the first chunk from each video
        color_selection: Attribute to color points by (e.g., 'song_name', 'artist')
        show_lines: Boolean to show connecting lines between chunks
        show_numbers: Boolean to show chunk numbers on points

    Returns:
        Altair chart object or None if visualization couldn't be created
    """
    # Load all embeddings
    all_embeddings = load_embeddings(embeddings_dir)
    if not all_embeddings:
        st.error("No embeddings found. Please check the embeddings directory.")
        return None

    # Prepare embeddings for UMAP
    embedding_array, video_ids, chunk_numbers = prepare_embeddings_for_umap(
        all_embeddings, embedding_type, exclude_last_chunk, only_first_chunk
    )

    # Check if we have any embeddings to visualize
    if len(embedding_array) == 0:
        st.error(
            f"No embeddings found for type '{embedding_type}'. Try a different embedding type."
        )
        return None

    # Get metadata for all video IDs
    unique_video_ids = list(set(video_ids))
    metadata_by_video = get_metadata_from_csv(unique_video_ids)

    # Reduce dimensionality with UMAP
    with st.spinner(
        f"Reducing dimensionality with UMAP (embedding type: {embedding_type})..."
    ):
        reducer = UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
        embedding_2d = reducer.fit_transform(embedding_array)

    # Create a DataFrame for Altair with all metadata
    df_data = {
        "x": embedding_2d[:, 0],
        "y": embedding_2d[:, 1],
        "video_id": video_ids,
        "chunk_number": chunk_numbers,
    }

    # Create a mapping from each video_id to its metadata
    # This ensures consistent metadata for all chunks from the same video
    for column in [
        "song_name",
        "artist",
        "maqam",
        "type",
        "electric",
        "vintage",
        "link",
    ]:
        column_values = []
        for vid in video_ids:
            # Get metadata for this video ID
            metadata = metadata_by_video.get(vid, {})
            value = metadata.get(column, "Unknown")
            column_values.append(value)
        df_data[column] = column_values

    # Create the DataFrame
    df = pd.DataFrame(df_data)

    # Apply artist filter if provided and not empty
    if artist_filter and len(artist_filter) > 0:
        st.info(f"Filtering by artists: {', '.join(artist_filter)}")
        total_points_before_artist_filter = len(df)
        unique_songs_before_artist_filter = df["song_name"].nunique()

        # Filter by a list of artists (case-sensitive, ensure metadata is consistent or handle case in get_all_artists_from_csv)
        df = df[df["artist"].isin(artist_filter)]
        
        filtered_points_after_artist_filter = len(df)
        unique_songs_after_artist_filter = df["song_name"].nunique()

        st.info(f"Filtered from {total_points_before_artist_filter} points to {filtered_points_after_artist_filter} points based on artist selection.")
        st.info(
            f"Filtered from {unique_songs_before_artist_filter} songs to {unique_songs_after_artist_filter} songs based on artist selection."
        )

        if filtered_points_after_artist_filter == 0:
            st.warning(
                f"No data points remain after filtering for selected artists: {', '.join(artist_filter)}"
            )
            # Listing all available artists might be too much if the list is long.
            # The multiselect itself shows available artists.
            return None

    # Sort the DataFrame by video_id and chunk_number for the line paths
    df = df.sort_values(["video_id", "chunk_number"])

    # Base chart
    base = alt.Chart(df).encode(
        x=alt.X("x:Q", title="UMAP Dimension 1"),
        y=alt.Y("y:Q", title="UMAP Dimension 2"),
    )

    # Create lines between consecutive chunks
    lines_data = []
    if show_lines:
        for vid in df["video_id"].unique():
            vid_df = df[df["video_id"] == vid].sort_values("chunk_number")
            if len(vid_df) > 1:
                for i in range(len(vid_df) - 1):
                    line_data = {
                        "x1": vid_df.iloc[i]["x"],
                        "y1": vid_df.iloc[i]["y"],
                        "x2": vid_df.iloc[i + 1]["x"],
                        "y2": vid_df.iloc[i + 1]["y"],
                    }
                    # Add all metadata columns
                    for col in [
                        "song_name",
                        "artist",
                        "maqam",
                        "type",
                        "electric",
                        "vintage",
                        "link",
                    ]:
                        line_data[col] = vid_df.iloc[i][col]
                    lines_data.append(line_data)

    # Create a DataFrame for the lines
    lines_df = pd.DataFrame(lines_data) if lines_data else pd.DataFrame()

    # Create the lines layer if we have line data
    lines = None
    if not lines_df.empty and show_lines:
        lines = (
            alt.Chart(lines_df)
            .mark_line(opacity=0.5, strokeWidth=1.5)
            .encode(
                x="x1:Q",
                y="y1:Q",
                x2="x2:Q",
                y2="y2:Q",
                color=alt.Color(
                    f"{color_selection}:N",
                    legend=None,
                ),
                tooltip=[
                    "song_name:N",
                    "artist:N",
                    "maqam:N",
                    "type:N",
                    "electric:N",
                    "vintage:N",
                ],
            )
        )

    # Create the points layer
    points = base.mark_circle(size=100).encode(
        color=alt.Color(
            f"{color_selection}:N",
            legend=alt.Legend(title=color_selection.replace("_", " ").title()),
        ),
        tooltip=[
            "song_name:N",
            "artist:N",
            "maqam:N",
            "type:N",
            "electric:N",
            "vintage:N",
            "chunk_number:Q",
            "link:N",
        ],
    )

    # Create the text layer for chunk numbers if requested
    text = None
    if show_numbers:
        text = base.mark_text(
            align="center", baseline="middle", dy=-10, fontSize=10
        ).encode(
            text="chunk_number:N",
            color=alt.value("black"),
        )

    # Combine the layers
    layers = [points]
    if lines is not None:
        layers.append(lines)
    if text is not None:
        layers.append(text)

    # Create the final chart
    chart = (
        alt.layer(*layers)
        .properties(
            width=700,
            height=500,
            title=f"MAEST Audio Embeddings - {embedding_type.upper()} Tokens",
        )
        .interactive()
    )

    return chart


# Callback functions for artist filter UI
def manage_artist_toggle():
    available_artists = st.session_state.get('available_artists_for_viz', [])
    if not available_artists:
        return

    if len(st.session_state.selected_artists_for_viz) == len(available_artists):
        st.session_state.selected_artists_for_viz = []
    else:
        st.session_state.selected_artists_for_viz = available_artists[:]
    # When toggling, always turn off quick focus as its state might become inconsistent
    st.session_state.quick_focus_artist_selectbox_value = "(Focus Off)"

def manage_quick_focus_change():
    # This function is called when the quick_focus_artist_selectbox's value changes.
    # The new value is in st.session_state.quick_focus_artist_selectbox_value
    focused_artist = st.session_state.quick_focus_artist_selectbox_value

    if focused_artist != "(Focus Off)":
        st.session_state.selected_artists_for_viz = [focused_artist]
    # If focus is turned off, selected_artists_for_viz is NOT automatically changed here.
    # The user would then use the multiselect or toggle to change the selection further.
    # This means selected_artists_for_viz will still hold the single focused artist until another action changes it.

def manage_multiselect_change():
    # This function is called when the artist_multiselect_widget's value changes.
    # The new value is in st.session_state.artist_multiselect_widget_value
    st.session_state.selected_artists_for_viz = st.session_state.artist_multiselect_widget_value
    
    # If user interacts with multiselect, and the current selection doesn't match a single focused artist,
    # then reset the quick focus selectbox to "(Focus Off)".
    current_selectbox_val = st.session_state.get('quick_focus_artist_selectbox_value', "(Focus Off)")
    if current_selectbox_val != "(Focus Off)":
        is_multiselect_matching_focus = (
            len(st.session_state.selected_artists_for_viz) == 1 and 
            st.session_state.selected_artists_for_viz[0] == current_selectbox_val
        )
        if not is_multiselect_matching_focus:
            st.session_state.quick_focus_artist_selectbox_value = "(Focus Off)"

def embedding_visualizer_ui():
    """
    Streamlit UI for the embedding visualizer
    """

    # Get the project directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)

    # Set default embeddings directory
    default_embeddings_dir = os.path.join(project_dir, "data", "embeddings")

    # Sidebar for configuration
    st.sidebar.header("Visualization Settings")

    # Embeddings directory input
    embeddings_dir = st.sidebar.text_input(
        "Embeddings Directory", value=default_embeddings_dir
    )

    # Embedding type selection
    embedding_type = st.sidebar.selectbox(
        "Embedding Type",
        ["cls", "dist", "avg", "combined"],
        index=0,
        help="Type of embedding to visualize",
    )

    # Artist Filter Section
    st.session_state.available_artists_for_viz = get_all_artists_from_csv()

    if not st.session_state.available_artists_for_viz:
        st.sidebar.warning("No artists found in metadata to filter by.")
        artist_filter_for_visualization = []
    else:
        # Initialize session state for selected artists and focus selectbox if they don't exist
        if 'selected_artists_for_viz' not in st.session_state:
            st.session_state.selected_artists_for_viz = st.session_state.available_artists_for_viz[:]
        if 'quick_focus_artist_selectbox_value' not in st.session_state:
            st.session_state.quick_focus_artist_selectbox_value = "(Focus Off)"
        if 'artist_multiselect_widget_value' not in st.session_state: # For direct binding from multiselect
            st.session_state.artist_multiselect_widget_value = st.session_state.selected_artists_for_viz[:]

        st.sidebar.subheader("Artist Filter")

        # Ensure selected_artists_for_viz is always a subset of available_artists_for_viz
        # This handles cases where CSV might change and previously selected artists are no longer available.
        st.session_state.selected_artists_for_viz = [
            artist for artist in st.session_state.selected_artists_for_viz 
            if artist in st.session_state.available_artists_for_viz
        ]
        # If selection became empty and it wasn't intentionally emptied, re-select all
        if not st.session_state.selected_artists_for_viz and st.session_state.available_artists_for_viz and not st.session_state.get('user_deselected_all', False):
             st.session_state.selected_artists_for_viz = st.session_state.available_artists_for_viz[:]
        st.session_state.pop('user_deselected_all', None) # Reset flag

        # Update multiselect key to reflect current selection state for proper rendering
        st.session_state.artist_multiselect_widget_value = st.session_state.selected_artists_for_viz[:]

        col1_toggle, col2_focus = st.sidebar.columns([1,2]) # Adjust column width ratio if needed

        with col1_toggle:
            st.button("Toggle All", on_click=manage_artist_toggle, key="toggle_artists_button")

        with col2_focus:
            focus_options = ["(Focus Off)"] + st.session_state.available_artists_for_viz
            st.selectbox(
                "Quick Focus",
                options=focus_options,
                key="quick_focus_artist_selectbox_value", # Bind directly to session state key
                on_change=manage_quick_focus_change,
                help="Select one artist to focus on, deselecting others."
            )

        # Artist Multiselect
        st.sidebar.multiselect(
            "Select Artists:",
            options=st.session_state.available_artists_for_viz,
            key="artist_multiselect_widget_value", # Bind directly to session state key
            on_change=manage_multiselect_change,
            help="Select one or more artists to include in the visualization."
        )
        # The source of truth for filtering is selected_artists_for_viz, updated by callbacks
        artist_filter_for_visualization = st.session_state.selected_artists_for_viz

    # Chunk filtering options
    exclude_last_chunk = st.sidebar.checkbox(
        "Exclude Last Chunk", value=False, help="Exclude the last chunk from each song"
    )

    only_first_chunk = st.sidebar.checkbox(
        "Only First Chunk",
        value=False,
        help="Only include the first chunk from each song",
    )

    st.sidebar.markdown("---")  # Separator
    st.sidebar.subheader("Chart Appearance")

    # Color by selection
    color_selection = st.sidebar.selectbox(
        "Color by:",
        ["song_name", "artist", "maqam", "type", "electric", "vintage"],
        index=0,
        help="Attribute to color points by",
    )

    # Toggle for showing connecting lines
    show_lines = st.sidebar.checkbox("Show connecting lines", value=True)

    # Toggle for showing chunk numbers
    show_numbers = st.sidebar.checkbox("Show chunk numbers", value=True)

    # Create a placeholder for the visualization
    chart_placeholder = st.empty()

    # Automatically generate visualization based on current settings
    if not os.path.exists(embeddings_dir):
        st.error(f"Embeddings directory does not exist: {embeddings_dir}")
    else:
        with st.spinner("Generating visualization..."):
            chart = create_embedding_visualization(
                embeddings_dir=embeddings_dir,
                embedding_type=embedding_type,
                exclude_last_chunk=exclude_last_chunk,
                artist_filter=artist_filter_for_visualization, # Use the new list-based filter
                only_first_chunk=only_first_chunk,
                color_selection=color_selection,
                show_lines=show_lines,
                show_numbers=show_numbers,
            )

            if chart:
                # Display the chart in the placeholder
                chart_placeholder.altair_chart(chart, use_container_width=True)

                # Download button has been removed as per user request.


if __name__ == "__main__":
    embedding_visualizer_ui()
